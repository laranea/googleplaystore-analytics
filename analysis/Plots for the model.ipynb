{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prerequisite : Need to run the NLP model notebook "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This plot shows the word count before preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_before_stop_words = reviews.apply(normalize)\n",
    "\n",
    "fig = plt.figure(figsize = (10,4))\n",
    "plt.gcf().subplots_adjust(bottom=0.15)\n",
    "plt.tight_layout()\n",
    "plt.title('Top 30 words in review before preprocessing')\n",
    "plt.xlabel('Words')\n",
    "plt.ylabel('Counts')\n",
    "\n",
    "\n",
    "word_counts = list(itertools.chain(*token_before_stop_words))\n",
    "freq_dist = FreqDist(word_counts)\n",
    "freq_dist.plot(30, cumulative=False)\n",
    "\n",
    "plt.show()\n",
    "fig.savefig('../word_count_before_preprocess.png', bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This plot for review length will be used in the report. However, for the purpose of presentation, I will remove the outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns \n",
    "processed_df['Review Length'] = processed_df[\"Tokens\"].apply(lambda x: len(x))\n",
    "\n",
    "processed_df.tail()\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize = (25,4))\n",
    "plt.tight_layout()\n",
    "plt.legend()\n",
    "sns.countplot(processed_df['Review Length'])\n",
    "\n",
    "plt.xticks(rotation = 90)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This plot will be used for the presentation purpose in which the outliers will be removed.\n",
    "\n",
    "IQR = Q3 - Q1 = 26-6 = 20 Upper_Bound = 26+1.5*20 = 56 Those review that have review length>56 will be removed from the plots for presentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns \n",
    "processed_df['Review Length'] = processed_df[\"Tokens\"].apply(lambda x: len(x))\n",
    "\n",
    "processed_df.tail()\n",
    "df['Review Length'].describe()\n",
    "\n",
    "fig = plt.figure(figsize = (10,4))\n",
    "plt.tight_layout()\n",
    "plt.legend()\n",
    "sns.countplot(processed_df[processed_df['Review Length']<56]['Review Length'])\n",
    "plt.xticks(rotation = 90)\n",
    "plt.title('Review Length Distribution')\n",
    "\n",
    "fig.savefig('../ReviewLength.png', bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here, we can see that people mostly like to make short review. However, it might be due to the fact that our preprocessing \n",
    "was unable to separate some words. Thus, there might be more words with a longer actual word length. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This plot shows the word count after preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (10,4))\n",
    "plt.tight_layout()\n",
    "plt.title('Top 30 words in review after preprocessing')\n",
    "plt.xlabel('Words')\n",
    "plt.ylabel('Counts')\n",
    "\n",
    "\n",
    "word_counts = list(itertools.chain(*tokens))\n",
    "freq_dist = FreqDist(word_counts)\n",
    "freq_dist.plot(30, cumulative=False)\n",
    "\n",
    "plt.show()\n",
    "fig.savefig('../freqDist.png', bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this part of the code, I edited a bit to get the csv with the compound scores inside. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = SentimentIntensityAnalyzer()\n",
    "def sentiment_polarity(s):\n",
    "    global analyzer\n",
    "    polarity_scores = analyzer.polarity_scores(s)\n",
    "    compound_score = polarity_scores[\"compound\"]\n",
    "    if compound_score >= 0.5:\n",
    "        label = \"Positive\"\n",
    "    elif compound_score > -0.05 and compound_score < 0.05:\n",
    "        label = \"Neutral\"\n",
    "    else:\n",
    "        label = \"Negative\"\n",
    "    return label, polarity_scores[\"neu\"], polarity_scores[\"pos\"], polarity_scores[\"neg\"],compound_score\n",
    "\n",
    "df = processed_df\n",
    "df[\"Sentiment\"], df[\"Neutral Proportion\"], df[\"Positive Proportion\"], df[\"Negative Proportion\"],df['Compound'] =  zip(*df[\"Review\"].apply(sentiment_polarity))\n",
    "df.sample(3)\n",
    "\n",
    "df.to_csv(\"../Project/compound.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plots made by using the compound csv can be found in visualization_project_V3.rmd"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
